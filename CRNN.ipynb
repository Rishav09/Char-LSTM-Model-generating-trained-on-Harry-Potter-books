{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open text file and read in data as `text`\n",
    "with open('anna.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = tuple(set(text))\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "encoded = np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 36, 57, 25, 14, 64, 35, 19, 34, 42, 42, 42, 82, 57, 25, 25, 26,\n",
       "       19,  8, 57, 72,  4, 49,  4, 64, 45, 19, 57, 35, 64, 19, 57, 49, 49,\n",
       "       19, 57, 49,  4, 73, 64, 79, 19, 64, 75, 64, 35, 26, 19, 62, 21, 36,\n",
       "       57, 25, 25, 26, 19,  8, 57, 72,  4, 49, 26, 19,  4, 45, 19, 62, 21,\n",
       "       36, 57, 25, 25, 26, 19,  4, 21, 19,  4, 14, 45, 19, 52, 27, 21, 42,\n",
       "       27, 57, 26, 29, 42, 42, 65, 75, 64, 35, 26, 14, 36,  4, 21])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    \n",
    "    # Initialize the the encoded array\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    #\n",
    "    #print(one_hot.shape)\n",
    "    # Fill the appropriate elements with ones\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    \n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "test_seq = np.array([[3, 5, 1]])\n",
    "\n",
    "one_hot = one_hot_encode(test_seq, 8)\n",
    "\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = No. of sequences per batch\n",
    "def get_batches(arr,batch_size,seq_length):\n",
    "    batch_size_total = batch_size * seq_length\n",
    "    n_batches = len(arr) // batch_size_total\n",
    "    arr = arr[:n_batches * batch_size_total]\n",
    "    arr = arr.reshape((batch_size,-1))\n",
    "    \n",
    "    for n in range(0,arr.shape[1],seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        y = np.roll(x,-1)\n",
    "#         y = np.zeros_like(x)\n",
    "#         try:\n",
    "#             y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
    "#         except IndexError:\n",
    "#             y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 8, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[50 36 57 25 14 64 35 19 34 42 42 42 82 57 25 25 26 19  8 57 72  4]\n",
      " [45 52 21 19 14 36 57 14 19 57 14 14 35 57 16 14 64 74 19 36 64 35]\n",
      " [64 21 74 19 52 35 19 57 19  8 52 64 17 19 36 64 19 57 75 52  4 74]\n",
      " [45 19 14 36 64 19 16 36  4 64  8 19 14 36 52 62 10 36 19 36  4 74]\n",
      " [19 45 57 27 19 36 64 35 19 14 64 57 35  7 45 14 57  4 21 64 74 17]\n",
      " [16 62 45 45  4 52 21 19 57 21 74 19 57 21 57 49 26 45  4 45 17 19]\n",
      " [19 24 21 21 57 19 36 57 74 19 45 57  4 74 19 14 36 57 14 19 81 52]\n",
      " [70  3 49 52 21 45 73 26 29 19 13 67 62 14 19 44 14 36 64 26 44 19]]\n",
      "\n",
      "y\n",
      " [[36 57 25 14 64 35 19 34 42 42 42 82 57 25 25 26 19  8 57 72  4]\n",
      " [52 21 19 14 36 57 14 19 57 14 14 35 57 16 14 64 74 19 36 64 35]\n",
      " [21 74 19 52 35 19 57 19  8 52 64 17 19 36 64 19 57 75 52  4 74]\n",
      " [19 14 36 64 19 16 36  4 64  8 19 14 36 52 62 10 36 19 36  4 74]\n",
      " [45 57 27 19 36 64 35 19 14 64 57 35  7 45 14 57  4 21 64 74 17]\n",
      " [62 45 45  4 52 21 19 57 21 74 19 57 21 57 49 26 45  4 45 17 19]\n",
      " [24 21 21 57 19 36 57 74 19 45 57  4 74 19 14 36 57 14 19 81 52]\n",
      " [ 3 49 52 21 45 73 26 29 19 13 67 62 14 19 44 14 36 64 26 44 19]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# printing out the first 10 items in a sequence\n",
    "print('x\\n', x[:22, :22])\n",
    "print('\\ny\\n', y[:21, :21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No gpu\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    print(\"Using gpu\")\n",
    "else:\n",
    "    print(\"No gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self,tokens,n_hidden=256,n_layers=2,drop_prob=0.5,lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(r_output)\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self,batch_size):\n",
    "        weight = next(self.parameters()).data    \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(\n",
      "  (lstm): LSTM(83, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (fc): Linear(in_features=512, out_features=83, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n_hidden=512\n",
    "n_layers=2\n",
    "\n",
    "net = model(chars, n_hidden, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
    "    ''' Training a network \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        net: CharRNN network\n",
    "        data: text data to train the network\n",
    "        epochs: Number of epochs to train\n",
    "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
    "        seq_length: Number of character steps per mini-batch\n",
    "        lr: learning rate\n",
    "        clip: gradient clipping\n",
    "        val_frac: Fraction of data to hold out for validation\n",
    "        print_every: Number of steps for printing training and validation loss\n",
    "    \n",
    "    '''\n",
    "    net.train()\n",
    "    \n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # create training and validation data\n",
    "    val_idx = int(len(data)*(1-val_frac))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    \n",
    "    counter = 0\n",
    "    n_chars = len(net.chars)\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        h = net.init_hidden(batch_size)\n",
    "        \n",
    "        for x, y in get_batches(data, batch_size, seq_length):\n",
    "            counter += 1\n",
    "            \n",
    "            # One-hot encode our data and make them Torch tensors\n",
    "            x = one_hot_encode(x, n_chars)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            if(train_on_gpu):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = net(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "            \n",
    "            # loss stats\n",
    "            if counter % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                net.eval()\n",
    "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
    "                    # One-hot encode our data and make them Torch tensors\n",
    "                    x = one_hot_encode(x, n_chars)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    \n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "                    \n",
    "                    inputs, targets = x, y\n",
    "                    if(train_on_gpu):\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                    output, val_h = net(inputs, val_h)\n",
    "                    val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
    "                \n",
    "                    val_losses.append(val_loss.item())\n",
    "                \n",
    "                net.train() # reset to train mode after iterationg through validation data\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 10... Loss: 3.2385... Val Loss: 3.1787\n",
      "Epoch: 1/2... Step: 20... Loss: 3.1454... Val Loss: 3.1333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-678cb265b8df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-89-589d6fdd5e08>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, data, epochs, batch_size, seq_length, lr, clip, val_frac, print_every)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m# get the output from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tflow/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-8bce5a064d14>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mr_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tflow/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tflow/lib/python3.6/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tflow/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;31m# Activation functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tflow/lib/python3.6/site-packages/torch/nn/_functions/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, input, p, train, inplace)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbernoulli_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "seq_length = 100\n",
    "n_epochs = 2 # start smaller if you are just testing initial behavior\n",
    "\n",
    "# train the model\n",
    "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the name, for saving multiple files\n",
    "model_name = 'rnn_20_epoch.net'\n",
    "\n",
    "checkpoint = {'n_hidden': net.n_hidden,\n",
    "              'n_layers': net.n_layers,\n",
    "              'state_dict': net.state_dict(),\n",
    "              'tokens': net.chars}\n",
    "\n",
    "with open(model_name, 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(net, char, h=None, top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "            Returns the predicted character and the hidden state.\n",
    "        '''\n",
    "        \n",
    "        # tensor inputs\n",
    "        x = np.array([[net.char2int[char]]])\n",
    "        x = one_hot_encode(x, len(net.chars))\n",
    "        inputs = torch.from_numpy(x)\n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        # detach hidden state from history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # get the output of the model\n",
    "        out, h = net(inputs, h)\n",
    "\n",
    "        # get the character probabilities\n",
    "        p = F.softmax(out, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "        \n",
    "        # get top characters\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(net.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        # select the likely next character with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        \n",
    "        # return the encoded value of the predicted char and the hidden state\n",
    "        return net.int2char[char], h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(net, size, prime='The', top_k=None):\n",
    "        \n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.cpu()\n",
    "    \n",
    "    net.eval() # eval mode\n",
    "    \n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    h = net.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, h = predict(net, ch, h, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "    \n",
    "    # Now pass in the previous character and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna  t   ea t ataan na  e     ea aa  an ee nte       e etneaaat   e eaa n eenae ae ttten  aennttttae  an et n ett ttene ae a n   ta a ne  nt   e  e  nt e  a n nt e nntte  a   a teeeat ta ee  t   tn te eet  eteett      n  et a    ee n   a teaaetana a  e  teeetaeta tae e aneenene a ena t ent nnee  ea eee ete aen een an aa n taa   tn neaen     eee  tne aen   e n  nn entt  t   e  t tena nte nant enena atn t tnt t aaeneeeaneae tae   aa  t an ee ee   ae an eteaaa tna a taaee a et ant ee a n naneeaat enen ta at et aa etet e   eaetn a eeenn  ee a n aeet  t ea  nn nnaettee   t nt  ean  n t at aent nnn  tnat aa an nt eatenee at aettaae aae ante  naennnn   tta  a  te etetaaee ea naa a a e ete ttaeae tea  tt a at   a e  a n teeea ne  tn et aennee attta anan n   eetane n enane netnaaaeeaant e   eaa  tn ne n  t n  eeaatata  e  nn  n neann ne   nettn t aan nae eea ta tt nt e an  e  atta en  tt    at ttae ata    a  a eee na n tt ne na a teeenanttte  t t   ee a ate   e   aa taaen n  neet aa   eteeee  ae at\n"
     ]
    }
   ],
   "source": [
    "print(sample(net, 1000, prime='Anna', top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rnn_20_epoch.net', 'rb') as f:\n",
    "    checkpoint = torch.load(f, map_location=lambda storage, loc: storage)\n",
    "    \n",
    "loaded = model(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
    "loaded.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voldermort, how he did not know how the clearing were\n",
      "not sure how much he had ever seen in his mind, where they waited,\n",
      "but his most father had still had an arrangen thing he had been. The silence flew to the\n",
      "bedrooms and looked away. He could see her with the crowd on the first floor. A step with a\n",
      "long, speedy soft, a flash of light and she wrestled a look of great roar of\n",
      "shadow of the compartment without a strange. A few of our feet seemed to be sitting in the\n",
      "concentration. Harry was sorry for him to say, before Harry would never have been\n",
      "able to follow hing her to Harry and Ron, Hagrid had been carrying\n",
      "trying to get through the ground with a porente comprimerth. After a\n",
      "minute, Harry could hear a gleamed cold and and her shoes and cheeks\n",
      "and two of the fourth-second parchment that was standing in\n",
      "front of the door, as though ir hear whispering, “I think he’d be\n",
      "able to say the permission between your aunt with the bashet as a cage\n",
      "with a strangled contendarts of his proper sentence. This is none\n",
      "of us to giggle.”\n",
      "“What’s that?” he said softly. Harry could hear a short, black shrug on his shoulder, staring\n",
      "at the steaky weed.\n",
      "“I think I’m,” said Harry.\n",
      "“He discuss you.”\n",
      "Snape winked.\n",
      "His scar was spreading as the bell rang.\n",
      "They had never believed with a spark toward the crowd to produce\n",
      "his powers and that they were being almost almost a fine car which shouted,\n",
      "“I’m sorry that he’s nearly troubled in the Daily Prophet, we would\n",
      "like to be alone in the fire to allow trem to how he was, which he’s been thrown up to the school and we can\n",
      "crying the street to the summer to the boy, think about him. I was\n",
      "thrown up time, we’ve got there tonight then you say that we are this talest to\n",
      "you. I’m going to bed with him, and I was asking to much hurter\n",
      "than the students the fourteen years time. . . .”\n",
      "“He did try and tell them what the Death Eaters were gave a pet\n",
      "of it ask where he’s bothering in the money who seems for you to try\n",
      "and see you back in them!”\n",
      "“Yeah,” said Hagrid. “That’s why he has. If they are not worse,\n",
      "I will be in my office, a whan he wanted a little charm in the stop,\n",
      "and I can’t be in the Daily Prophet anymore. . . .”\n",
      "“We’re there,” said George, staring at her again. “That didn’t set him back, the Merope will be able to thought that I was going to stop them to come at all. In fact, indeed believed to\n",
      "tell you how to get off all the time with him, so hurry you’ve heard\n",
      "of you.”\n",
      "Harry had to take his eyes out of its and dancing toward the bar,\n",
      "bowing up but there was an undergrown lip with her hooked lights and settled\n",
      "it into the face. It was a sign of crimioals. He was like this, but she\n",
      "was sure that some of the countryside had been too.\n",
      "“Well, we’ve been at all,” said Hermione impariently. “You’ve hurtled a\n",
      "cousle with his memory without trapped — two things in there,\n",
      "wasn’t she?”\n",
      "“You will stop them all taking to my private spinnings around the class, you will be able\n",
      "to speak it for the protection in your” —” said Ginny impatiently. “I’m sorry,\n",
      "I don’t think that this has had betnehed him, and it’s all right. . . . Why don’t\n",
      "I’m going to decide is what we want, I saw, it’ll be stragging about the same assortment of things today with a\n",
      "cat without a creature —”\n",
      "Harry’s heart said, thinking hard inside his scar, which he had\n",
      "started. Harry, hooking around at the teachers to let him but the car\n",
      "while any silvery woman. They were still there.\n",
      "“Treat on the box,” he said quietly.\n",
      "“This is an order of my dear brats contant today,” said Harry.\n",
      "“He doesn’t want any idea,” said Harry. “How do you do that? You anyway, to the ball on the thing to be coming and staying in here —”\n",
      "“Three doors?” shouted Professor McGonagall. “You do, thank you all to talk to this.”\n",
      "“What’s that?” asked Harry, who was still\n",
      "standing in the fire as a small purple trick stopped slightly. “Yeah, will it?”\n",
      "Ron gasped. “I told you ter take you along with him — what was that supposed to do?”\n",
      "Then he said, “I suppose you didn’t see him too. If he had to tell\n",
      "them, the thing has always seen how the prisoners is had somehow to do the power from\n",
      "her.”\n",
      "“How d’you know about this?”’s shooked them all the second\n",
      "time before several pairs. “What’s up, if I have not been able to discover then how to concernd it from\n",
      "my seven o’clock they clearly didn’t want to go backward, where\n",
      "a summer? He was the only thought you’ll be seeing them, that’s where you did. I did the\n",
      "word of the same thing, to call them the thing it is, and he’s got ten frighteneds of magical\n",
      "chilled the boggarts. I won’t let him crouch so much me —”\n",
      "“Hermione?”\n",
      "Harry sat down, staring at Harry.\n",
      "\n",
      "“What do I do?”\n",
      "“Well, if they are. I’ve got a little closer!”\n",
      "Harry turnedhard at his feet. Harry saw his features closed at her sharp teacher. He\n",
      "was while to seize a pair of strained streaks of pains, a long, black\n",
      "stone, staring into the silver stone street toward that. Harry couldn’t\n",
      "move.\n",
      "Harry, who had started to turn, but he’d seize his hand into the\n",
      "air, the trapdoor burning her window, and the stone ball sway through the greenhouses. The whispering were all thrown over them.\n",
      "“I’m not sure I doubt it was all right —”\n",
      "\n",
      "\n",
      "218\n",
      "\n",
      "\n",
      "\n",
      "FLIGHT OF THE FAT LADY\n",
      "“Well, I’ll be that badges at magic,” said Red indivally, “and\n",
      "then, if he won’t help you, and it’s not an insent troll —”\n",
      "He was thrilling the crowd, his heart waved, and the three of them walked over.\n",
      "The common room was to be too lucky to say, “What are that safe if we can see the\n",
      "committat?”\n",
      "“Yes, it’s as if it’s the secret did to start that tall bat of security\n",
      "bruthers, the tasks of welcome would be a few months ofother and then we called you today. That\n",
      "was the only ones would be fore a lucky clean process.”\n",
      "“I saw it head her all over the sime for more times the others we\n",
      "have a crime on this open,” said Dumbledore.\n",
      "“I will take him out of this with the same scatheding form!”\n",
      "“Harry!” said Harry, his eyes shoning and slamming the door\n",
      "behind him. “Haven’t you gone a bit much of a good time?”\n",
      "“What’s going on?” said Harry, as the whistle was trying to sittan.\n",
      "“Harry,” said Moody, “that’s his own family.”\n",
      "\n",
      "“What would you know?” said Ron. “Harry,” she said, speaking factly and some step withing their step\n",
      "to the desks.\n",
      "“You should have seen him anymore? And I think they haven’t been a fir completely to see it well when he is. . . .”\n",
      "They went out of the window.\n",
      "“Transfiguration we’re talking about!” she said in a low voice.\n",
      "“Yeah, that’s right,” said Harry in an undertone; he had to be able\n",
      "to stay to anyone from her best too; the witch of them arrived, then the\n",
      "class thought he had to be the other two teaching in a shiny pot and\n",
      "spot the passage to the staff table. He seemed to shall see, and were both\n",
      "convincing his wand to acheal his feet at Harry’s beard.\n",
      "“You’re standing in the concintrets only one whole first person to get them along,\n",
      "Potter,” said Professor Umbridge impatiently. “I don’t think he\n",
      "seems to want to go.”\n",
      "“Well, I shouldn’t’ve been alone,” he said quietly. They had not\n",
      "backed toward them. “I’m not saying he has been trying to give\n",
      "the power to get through though!”\n",
      "“What happened to you?” said Harry, smirking, but his heart stared at them. The whole start of the people were already, still playing her face\n",
      "was twelve buttons as he cooled through him. They had been a sudden, bareling of his being\n",
      "carried through the streets behind him, but his heart was langed\n",
      "behind the statue of his family.\n",
      "The closed was that his foreers was now standing behind his face,\n",
      "trying to speak all him, he had a seeping firelegmed horrible steps at\n",
      "the foot of the stairs, which he was chosen of talking and the face\n",
      "that was not the only ones who was still staring at her with dressing street, and a strong chunk of his\n",
      "eyes looked almost as though he was so privately for the letter. In a\n",
      "deep black, somehot. Then he said, “Sirius’s gave as though I suppose I can’t, to go and told\n",
      "the Dursleys.” He was growing disporningly, “I’m not hiding intimad the point that is starting to see his plan\n",
      "anymore. And we’re able to get it. As I don’t care what I was going.”\n",
      "“Why don’t you stay in my old persons?” said Harry quietly.\n",
      "“He was telling you namey without these wizards though he\n",
      "wills’ve told the others for a bather on the care over it, and worked away to the school that\n",
      "must be his means on anything to me all soon, but he doesn’t care\n",
      "how he chose, it’s trying to get on it,” he added tonely. “He’s a straight.”\n",
      "Snow was starting to flick as though too many of them were still\n",
      "scarlying his wand on the floor.\n",
      "“Who is the pot to start improved?” Harry asked as he climbed a desperate\n",
      "voice shut back downstairs: “I’m going to have to tell the Dark Arts\n",
      "for the Dark Lord. It hasn’t comin’ and six terrible things too. It\n",
      "doesn’t make any cloak but have tore out of him.”\n",
      "“I’ve got that trappons, indeed, it seems to wait for me!” said\n",
      "Harry flatly.\n",
      "“I wing to go on the bell,” said Harry sharply. “They ask me to teach me half-breeds for thirteen years\n",
      "ago, is that wing? Though I can see his potion within too?”\n",
      "He looked at Harry, who was still looking sheepish with her head\n",
      "breezing with his bedroom. “It is time an hour ago, we can hear\n",
      "a copper commit of Magic Sticky along. His special chances wasn’t\n",
      "the same as yastering in the school schoolbooms. . . .”\n",
      "“I stayed,” said Harry sharply.\n",
      "He holding the corner with his wand told him to start the blow with his broomstick. Tonks was\n",
      "sitting there with his eyes werewalled again, which students were\n",
      "botheding his stomach at the foot of the stairs.\n",
      "Harry cried the trunk and the white foreside was spreading a single weard as though it were\n",
      "such an a cheerful tough statue. He threw it into the air, taking his barred\n",
      "back out inside the cage; the car still spilled around his hand again. He she said, “It’d\n",
      "be too lot at her first time in front of you.”\n",
      "Harry shook his head to her face. “He’s the only person about\n",
      "what it would be able to get them on the train, should we saw\n",
      "while I saw you who say.”\n",
      "Snape shrieked anxiously at him from the crowd, though she\n",
      "stepped at all the way back to her chair and waited. “What are you\n",
      "going to get out of the front of your face? I don’t wart you, he will be still\n",
      "alarming.” He thought he had been distusted with silver sering of\n",
      "thick tanks.\n",
      "“Would you hear me?” asked Rot, who was laughing, and the table still hung of\n",
      "shadowy face turned around, a bright looking look at him, but a few moments later. She\n",
      "showed his wand. He led her, the street through the grounds. The\n",
      "water sprinted away from the wall. The strong moment the potion was this with a loud\n",
      "continuous sound while the street was followed by her face that they\n",
      "had never seen before he was about to get out, but Harry was able to go to the\n",
      "students that had her arm around him. The people of the water tabled\n",
      "his face, and therefore started whispering, his eyes standing behind him, and a\n",
      "long snout on his face as a gigantic leg, a list after a whisper became the\n",
      "ballew and clutching a stand out to see his scar the serious barn, he hoped they were so past. It said something about them any of his father hugged antichesters over the sound of the\n",
      "portrait hole that shook hardly at the side of the three were an argument about.\n",
      "“I want to be there,” said Harry in the show while; the crowds were now larger\n",
      "than his sereence.\n",
      "“Why was the crazing and having a spider, who can take the story?”\n",
      "“Yes, yes, we’ll talk to them,” said Hermione shortly.\n",
      "“Yes, I’m sirpled well,” said Ron. “There’s an impression if you couldn’t\n",
      "stay in the school to be certain, but that’s a class, that’s what you wanted to be\n",
      "complicated,” said Harry quietly.\n",
      "“It seems to be too much as well,” said Professor McGonagall, shut\n",
      "their face with her hands.\n",
      "“You see,” she said quickly. “If you don’t know what you could come\n",
      "and get a bit of a bit of the thing if I hardly come and do anything that stretcher around whatever he stopped.”\n",
      "He had to go to Hogwarts, because Harry had no idea what someone was down to say to\n",
      "seeing Harry too long that Hagrid had decided to be.\n",
      "\n",
      "“I decided we have no message with the Dark Lord?” said Ron, who had spoken and trying to flew away to the staff table.\n",
      "“I see,” said Ron tremulously. “What d’you mean? Hang the dementors? I want to go into to the\n",
      "crumpling room,” he said, shuffling the common room. “You’ll see how?”\n",
      "“Why didn’t I do a permase wizard, Hagrid?” said Harry, who\n",
      "was standing behind the trial again; in her voice, Hagrid waved at him, and a handshous to ask she had sent Harry both of them.\n",
      "\n",
      "\n",
      "277\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER FOURTEEN\n",
      "“You can tell us that, then?” called Ron; a sea of dragon seize her\n",
      "clean state was too badly to look as though he were a lot an explanation of Dumbledore’s sister’s faces and\n",
      "crunching for sixty times at him. “We’d better go and want a lot of\n",
      "wands for him. . . .”\n",
      "“I do with you,” said Hermione as the stone shades of breathing as\n",
      "the teachers were as though he had just swollen their homes fixed\n",
      "back into her bags. “I’m not allowed to search the door.”\n",
      "\n",
      "\n",
      "233\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER TWELVE\n",
      "“The same thing is.”\n",
      "Harry was suring him to the day of all team. Harry saw Ron see where he had been told in their\n",
      "troubles.\n",
      "“You can’t give my seats of guarding that boy’s going to think that\n",
      "I can tell you. Wormtail asks the same way as he deserved the train.\n",
      "I’ll have a greeth to give me a corridor that we are too seriously as\n",
      "well.” She left; the caretaker was staring toward the cheek.\n",
      "“You don’t know,” said Ginny. “We haven’t got a problem, there\n",
      "is a sudden charge of the teachers, and had so stupid if you could depart the task it was in a\n",
      "meeting, with too long with me, he was stupid anymore, weren’t it?\n",
      "And that’s the stroke, I don’t know.”\n",
      "“Why how?”\n",
      "“I don’t know what you’re doing,” said Sirius, “but I think it’s the\n",
      "only task about what’s going to do with ten signs of good students, and then I should think he’s\n",
      "sent more to him. If they don’t certainly try and say anything intracted!”\n",
      "“We were sitting in the fire on his bed. Harry, that’s what I\n",
      "was doing when I would’ve betrayed it!” he asked her.\n",
      "Hermione had already becomes so shortentively somehow\n",
      "headiced from behind the stronger of water, and she was stealing\n",
      "them toward him.\n",
      "“The Dark Lord!” said Snape. “He’s any more than this work\n",
      "about that!”\n",
      "Harry threw the brain out of his mouth, spitting along where they were climbing into the front door, then wiped the barrier silence.\n",
      "“Well, that’s not there, Privet Drive,” said Snape softly. “That’s the mind of the players and\n",
      "the security charges of the teachers.”\n",
      "“You could do anything stuck aloud,” she added anxiously. “When I saw\n",
      "my favorite school broken witness, which will bring the Department of\n",
      "Mysteries through this chocolate in my other attention to the Dark\n",
      "Lord, would it be trying to concentrate inside the trial, has stopped\n",
      "sick. He was the only thing I’d better telling him to take her to\n",
      "the dementors, which they were going to be such, and that monster and his most\n",
      "cheirly worles must be trolling too much more company. . . . It\n",
      "was the memory, it was that sounded like a bearden that had before; he was surprised\n",
      "and was too.\n",
      "He went on, though he was so thick what had happened at his\n",
      "foot.\n",
      "“I still don’t think that’s the only person who changed this time after a bit and take your since\n",
      "bed the trick? Why don’t you say how happy he had no seem?”\n",
      "“Yes,” said Harry. “He came back to himself.”\n",
      "He stopped, speaking, beaming, trying to close. “Yes, indeed, then, I suppose —\n",
      "there’s the only protection on his books for a wonder. It’s seen a lot of me to give you a little single tiny, and they wouldn’t believe\n",
      "it.”\n",
      "\n",
      "\n",
      "419\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER TWENTY-TWO\n",
      "\n",
      "THE DEPARTMENT\n",
      "OF MYSTERIES\n",
      "“It’s okay?” Harry said sharply, leaning over to speak, but Harry\n",
      "let out a blurred silver corridor of butterbeer and painting, her eyes\n",
      "warming and still fading trailing on the bedcoot for his bed to his students.\n",
      "“We’d better get through it in there. That was what you did,\n",
      "I can speak a good poor. I don’t know how much you’re going to\n",
      "stand that closed beside the Death Eaters at the student of\n",
      "again.”\n",
      "“You weren’t telling you which he was telling me, Madam Romames,” said Mrs. Figg impatientatly.\n",
      "“They says the moment we given him to do!”\n",
      "“Well, that doesn’t matter,” said Ron, looking fleatingly at Hermione.\n",
      "“I don’t think it must be any servant at a time,” she said, still wearing a step and shrinking against the wall. Harry could not have stopped;\n",
      "Harry shook his head; he had never seen him want to see it; then he\n",
      "remembered. He was last near the crowd, all of whom he then here\n",
      "her bacin coursy they had been staring all over his front door.\n",
      "He had never been, but there was no sign of anything whether he had\n",
      "seen that he had turned up at an answer. He was still there, because\n",
      "Harry was sure he wouldn’t have liked him, was trying to get out of\n",
      "here with his mouth, and his black hooded formation, a bit of starving, broomsticks he could see a second lowar but\n",
      "shouted and set off a centaur, but he shook.\n",
      "“How do we go behind?”\n",
      "“I’m trying to choose it. Wanting to be changed with me,” she\n",
      "shrugged.\n",
      "“Harry!” said Harry firmly. “You can’t talk through an anger\n",
      "on my family, all right? It has the best school filled the change of\n",
      "magic that matters are not there for a bit — how could you take a badge\n",
      "and see it? You don’t know about your favorite, that we do interest it, the stupid ward\n",
      "came in a defense of a complete courtear of thimseling students.\n",
      "It’s a little man we shouldn’t know, I don’t know what he might have\n",
      "deserted with a class outside his parents and have a letter in the\n",
      "witch, so they’ll see them. . . .”\n",
      "He strode away and stared straight forward, but he was sitting in the corridors toward the\n",
      "corridors, still gazing and stuck in a stop in the stone. He looked as\n",
      "though he would be able to fight it all.\n",
      "“Yes, thanks,” said Ron, looking around at Harry.\n",
      "“You know,” said Snape calmly.\n",
      "“If you are not satisfyen, though I centin the statue of the Dursleys haven’t seen\n",
      "me, and whatever there were stands in front of it. Anyway . . .”\n",
      "“What?”\n",
      "“No,” said Hermione, “we don’t care. This second year was an urgent second. We were a bit of torches in the\n",
      "world.”\n",
      "Harry looked around.\n",
      "“You can’t get into him, then?” Hermione whispered.\n",
      "“It’s a sont,” said Stan walkingly, looking at her, before he could have a cough\n",
      "the other. “However,” he said. “I haven’t been to see you for your school and\n",
      "trying to go in that trouble to get to his break, and to try and get\n",
      "it at home to me, and he was so well in which the Ministry’s gone to say the subject. I was the one who saw him. I wonder, I’d rather\n",
      "heard the dementors in front of you, was he?”\n",
      "“Yes . . .”\n",
      "“Wand up an owl that supposed to send them to a particularly sort\n",
      "of good if you could have settled a correct people who have been at all\n",
      "angry as how to get in there too many points from any cases and three\n",
      "murders on their story. He went out of the Great Hall to go, and hardly something when he had been a few\n",
      "points from Gryffindor.”\n",
      "Hermione spid out horror to her serious light.\n",
      "“Yis don’t be able to go on,” he said, stomping forward, and they\n",
      "pulled off Harry’s broom and spring around him and his face sworing out of it. “It’s not the first\n",
      "servant to but me to stand up to my school once we wanted to see the\n",
      "scene the number of year, but we’re not allowed to conceal a thought\n",
      "of more than a little crowd, and we don’t come.”\n",
      "“What was it?” said Harry, his mind still in front of her, but there\n",
      "was a gap in the bed into a small, gray, cold vanish silver with the\n",
      "ball, so that the straight badge shot through the bell rang again and he came to a\n",
      "halt and tried to get up, “you know that, won’t you? There have been\n",
      "some present at home to the Ministry, we’re not saying. . . .”\n",
      "The silence in the dark staircase had backled toward him,\n",
      "and shook his head sick at the spider.\n",
      "“There’s an undeen beautiful horrible thing,” said Ron, pacing the door over her shoulder;\n",
      "“and would you give to a break in the top case too much an exc\n"
     ]
    }
   ],
   "source": [
    "print(sample(loaded, 20000, top_k=5, prime=\"Voldermort\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
